{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.7097670442402224,
  "global_step": 2000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "learning_rate": 0.009966666666666667,
      "loss": 4.4213,
      "step": 10
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.009933333333333334,
      "loss": 3.9306,
      "step": 20
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0099,
      "loss": 3.9414,
      "step": 30
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.009866666666666668,
      "loss": 3.6414,
      "step": 40
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.009833333333333333,
      "loss": 3.8938,
      "step": 50
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0098,
      "loss": 3.7932,
      "step": 60
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.009766666666666667,
      "loss": 3.7704,
      "step": 70
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.009733333333333333,
      "loss": 3.8872,
      "step": 80
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0097,
      "loss": 3.7789,
      "step": 90
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.009666666666666667,
      "loss": 4.0212,
      "step": 100
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.009633333333333334,
      "loss": 3.944,
      "step": 110
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0096,
      "loss": 3.9921,
      "step": 120
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.009566666666666666,
      "loss": 3.9556,
      "step": 130
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.009533333333333335,
      "loss": 3.9642,
      "step": 140
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0095,
      "loss": 3.7977,
      "step": 150
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.009466666666666667,
      "loss": 3.9204,
      "step": 160
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.009433333333333334,
      "loss": 3.8946,
      "step": 170
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0094,
      "loss": 3.9559,
      "step": 180
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.009366666666666667,
      "loss": 3.811,
      "step": 190
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.009333333333333334,
      "loss": 3.8645,
      "step": 200
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.009300000000000001,
      "loss": 3.9017,
      "step": 210
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.009266666666666666,
      "loss": 3.873,
      "step": 220
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.009233333333333333,
      "loss": 3.9359,
      "step": 230
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0092,
      "loss": 3.9746,
      "step": 240
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.009166666666666667,
      "loss": 3.7671,
      "step": 250
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.009133333333333334,
      "loss": 3.9092,
      "step": 260
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0091,
      "loss": 3.958,
      "step": 270
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.009066666666666666,
      "loss": 4.0197,
      "step": 280
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.009033333333333334,
      "loss": 3.874,
      "step": 290
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.009000000000000001,
      "loss": 3.9454,
      "step": 300
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.008966666666666666,
      "loss": 3.9246,
      "step": 310
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.008933333333333333,
      "loss": 3.8717,
      "step": 320
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0089,
      "loss": 3.9825,
      "step": 330
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.008866666666666667,
      "loss": 3.9279,
      "step": 340
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.008833333333333334,
      "loss": 3.8331,
      "step": 350
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0088,
      "loss": 3.7954,
      "step": 360
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.008766666666666667,
      "loss": 3.8972,
      "step": 370
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.008733333333333333,
      "loss": 3.9296,
      "step": 380
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0087,
      "loss": 3.9298,
      "step": 390
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.008666666666666668,
      "loss": 3.9611,
      "step": 400
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.008633333333333333,
      "loss": 3.9094,
      "step": 410
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0086,
      "loss": 3.8873,
      "step": 420
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.008566666666666667,
      "loss": 3.8461,
      "step": 430
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.008533333333333334,
      "loss": 3.9048,
      "step": 440
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0085,
      "loss": 3.787,
      "step": 450
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.008466666666666667,
      "loss": 3.8059,
      "step": 460
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.008433333333333334,
      "loss": 3.6995,
      "step": 470
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0084,
      "loss": 3.9738,
      "step": 480
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.008366666666666666,
      "loss": 3.9013,
      "step": 490
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.008333333333333333,
      "loss": 3.7231,
      "step": 500
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0083,
      "loss": 3.8991,
      "step": 510
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.008266666666666667,
      "loss": 3.9273,
      "step": 520
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.008233333333333334,
      "loss": 4.0186,
      "step": 530
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.008199999999999999,
      "loss": 3.8383,
      "step": 540
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.008166666666666666,
      "loss": 3.7263,
      "step": 550
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.008133333333333334,
      "loss": 3.8393,
      "step": 560
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.008100000000000001,
      "loss": 3.9812,
      "step": 570
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.008066666666666666,
      "loss": 3.7555,
      "step": 580
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.008033333333333333,
      "loss": 3.8983,
      "step": 590
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.008,
      "loss": 3.7613,
      "step": 600
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.007966666666666667,
      "loss": 3.8457,
      "step": 610
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.007933333333333334,
      "loss": 3.8852,
      "step": 620
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0079,
      "loss": 3.8275,
      "step": 630
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.007866666666666666,
      "loss": 3.7272,
      "step": 640
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.007833333333333333,
      "loss": 4.0531,
      "step": 650
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0078000000000000005,
      "loss": 3.8608,
      "step": 660
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0077666666666666665,
      "loss": 3.9667,
      "step": 670
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.007733333333333333,
      "loss": 3.8095,
      "step": 680
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0077,
      "loss": 3.7733,
      "step": 690
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.007666666666666667,
      "loss": 3.7025,
      "step": 700
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.007633333333333333,
      "loss": 3.9097,
      "step": 710
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0076,
      "loss": 3.8214,
      "step": 720
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.007566666666666667,
      "loss": 3.755,
      "step": 730
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.007533333333333333,
      "loss": 3.8979,
      "step": 740
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0075,
      "loss": 3.6973,
      "step": 750
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0074666666666666675,
      "loss": 4.0042,
      "step": 760
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0074333333333333335,
      "loss": 3.818,
      "step": 770
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0074,
      "loss": 3.6819,
      "step": 780
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.007366666666666667,
      "loss": 3.8132,
      "step": 790
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.007333333333333333,
      "loss": 3.9078,
      "step": 800
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0073,
      "loss": 3.8621,
      "step": 810
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.007266666666666667,
      "loss": 3.8364,
      "step": 820
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.007233333333333334,
      "loss": 3.874,
      "step": 830
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0072,
      "loss": 3.8825,
      "step": 840
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.007166666666666667,
      "loss": 3.8791,
      "step": 850
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0071333333333333335,
      "loss": 3.7027,
      "step": 860
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0070999999999999995,
      "loss": 3.7173,
      "step": 870
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.007066666666666666,
      "loss": 3.7998,
      "step": 880
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.007033333333333334,
      "loss": 3.8062,
      "step": 890
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.006999999999999999,
      "loss": 3.8781,
      "step": 900
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.006966666666666667,
      "loss": 3.7039,
      "step": 910
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.006933333333333334,
      "loss": 3.7733,
      "step": 920
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0069,
      "loss": 3.873,
      "step": 930
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.006866666666666667,
      "loss": 3.7243,
      "step": 940
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.006833333333333334,
      "loss": 3.7511,
      "step": 950
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0068000000000000005,
      "loss": 3.9136,
      "step": 960
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0067666666666666665,
      "loss": 3.851,
      "step": 970
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.006733333333333333,
      "loss": 3.8575,
      "step": 980
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0067,
      "loss": 3.908,
      "step": 990
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.006666666666666666,
      "loss": 3.6744,
      "step": 1000
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.006633333333333333,
      "loss": 3.8839,
      "step": 1010
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.006600000000000001,
      "loss": 4.003,
      "step": 1020
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.006566666666666666,
      "loss": 3.8384,
      "step": 1030
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.006533333333333334,
      "loss": 3.8463,
      "step": 1040
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.006500000000000001,
      "loss": 3.8931,
      "step": 1050
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.006466666666666667,
      "loss": 3.8466,
      "step": 1060
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0064333333333333334,
      "loss": 3.9234,
      "step": 1070
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0064,
      "loss": 3.836,
      "step": 1080
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.006366666666666667,
      "loss": 3.8303,
      "step": 1090
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.006333333333333333,
      "loss": 3.9111,
      "step": 1100
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0063,
      "loss": 3.7291,
      "step": 1110
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.006266666666666667,
      "loss": 3.8242,
      "step": 1120
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.006233333333333333,
      "loss": 3.8669,
      "step": 1130
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0062,
      "loss": 3.9343,
      "step": 1140
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0061666666666666675,
      "loss": 3.6312,
      "step": 1150
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.006133333333333333,
      "loss": 3.8631,
      "step": 1160
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0061,
      "loss": 3.8331,
      "step": 1170
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.006066666666666667,
      "loss": 3.6044,
      "step": 1180
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.006033333333333334,
      "loss": 3.8251,
      "step": 1190
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.006,
      "loss": 3.7072,
      "step": 1200
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.005966666666666667,
      "loss": 3.6746,
      "step": 1210
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.005933333333333334,
      "loss": 3.8251,
      "step": 1220
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0059,
      "loss": 3.715,
      "step": 1230
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.005866666666666667,
      "loss": 3.6336,
      "step": 1240
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.005833333333333334,
      "loss": 3.6669,
      "step": 1250
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0058,
      "loss": 3.602,
      "step": 1260
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0057666666666666665,
      "loss": 3.8172,
      "step": 1270
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.005733333333333333,
      "loss": 3.6428,
      "step": 1280
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.005699999999999999,
      "loss": 3.6712,
      "step": 1290
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.005666666666666666,
      "loss": 3.6995,
      "step": 1300
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.005633333333333334,
      "loss": 3.68,
      "step": 1310
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.005600000000000001,
      "loss": 3.7239,
      "step": 1320
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.005566666666666667,
      "loss": 3.6716,
      "step": 1330
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.005533333333333334,
      "loss": 3.8318,
      "step": 1340
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0055000000000000005,
      "loss": 3.7605,
      "step": 1350
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0054666666666666665,
      "loss": 3.6119,
      "step": 1360
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.005433333333333333,
      "loss": 3.4545,
      "step": 1370
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0054,
      "loss": 3.5792,
      "step": 1380
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.005366666666666666,
      "loss": 3.7116,
      "step": 1390
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.005333333333333333,
      "loss": 3.7229,
      "step": 1400
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0053,
      "loss": 3.7213,
      "step": 1410
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.005266666666666666,
      "loss": 3.6334,
      "step": 1420
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.005233333333333333,
      "loss": 3.7069,
      "step": 1430
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.005200000000000001,
      "loss": 3.721,
      "step": 1440
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0051666666666666675,
      "loss": 3.5912,
      "step": 1450
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0051333333333333335,
      "loss": 3.5194,
      "step": 1460
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0051,
      "loss": 3.7061,
      "step": 1470
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.005066666666666667,
      "loss": 3.7741,
      "step": 1480
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.005033333333333333,
      "loss": 3.4955,
      "step": 1490
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.005,
      "loss": 3.7692,
      "step": 1500
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.004966666666666667,
      "loss": 3.7469,
      "step": 1510
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.004933333333333334,
      "loss": 3.5761,
      "step": 1520
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0049,
      "loss": 3.6005,
      "step": 1530
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.004866666666666667,
      "loss": 3.6526,
      "step": 1540
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.004833333333333334,
      "loss": 3.6145,
      "step": 1550
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0048,
      "loss": 3.7468,
      "step": 1560
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.004766666666666667,
      "loss": 3.7689,
      "step": 1570
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.004733333333333333,
      "loss": 3.5418,
      "step": 1580
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0047,
      "loss": 3.7173,
      "step": 1590
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.004666666666666667,
      "loss": 3.6487,
      "step": 1600
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.004633333333333333,
      "loss": 3.5865,
      "step": 1610
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0046,
      "loss": 3.6857,
      "step": 1620
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.004566666666666667,
      "loss": 3.6449,
      "step": 1630
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.004533333333333333,
      "loss": 3.5429,
      "step": 1640
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0045000000000000005,
      "loss": 3.7112,
      "step": 1650
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0044666666666666665,
      "loss": 3.6875,
      "step": 1660
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.004433333333333333,
      "loss": 3.5723,
      "step": 1670
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0044,
      "loss": 3.7216,
      "step": 1680
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.004366666666666666,
      "loss": 3.7183,
      "step": 1690
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.004333333333333334,
      "loss": 3.5972,
      "step": 1700
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0043,
      "loss": 3.8125,
      "step": 1710
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.004266666666666667,
      "loss": 3.6224,
      "step": 1720
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.004233333333333334,
      "loss": 3.5203,
      "step": 1730
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0042,
      "loss": 3.8128,
      "step": 1740
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.004166666666666667,
      "loss": 3.6569,
      "step": 1750
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0041333333333333335,
      "loss": 3.6987,
      "step": 1760
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0040999999999999995,
      "loss": 3.5316,
      "step": 1770
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.004066666666666667,
      "loss": 3.4669,
      "step": 1780
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.004033333333333333,
      "loss": 3.6895,
      "step": 1790
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.004,
      "loss": 3.7168,
      "step": 1800
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.003966666666666667,
      "loss": 3.5794,
      "step": 1810
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.003933333333333333,
      "loss": 3.8057,
      "step": 1820
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0039000000000000003,
      "loss": 3.8407,
      "step": 1830
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0038666666666666667,
      "loss": 3.615,
      "step": 1840
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0038333333333333336,
      "loss": 3.8469,
      "step": 1850
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0038,
      "loss": 3.7017,
      "step": 1860
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0037666666666666664,
      "loss": 3.7216,
      "step": 1870
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0037333333333333337,
      "loss": 3.5684,
      "step": 1880
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0037,
      "loss": 3.6783,
      "step": 1890
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0036666666666666666,
      "loss": 3.693,
      "step": 1900
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0036333333333333335,
      "loss": 3.6648,
      "step": 1910
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.0036,
      "loss": 3.6338,
      "step": 1920
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0035666666666666668,
      "loss": 3.6714,
      "step": 1930
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.003533333333333333,
      "loss": 3.495,
      "step": 1940
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0034999999999999996,
      "loss": 3.6074,
      "step": 1950
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.003466666666666667,
      "loss": 3.603,
      "step": 1960
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0034333333333333334,
      "loss": 3.6917,
      "step": 1970
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0034000000000000002,
      "loss": 3.3903,
      "step": 1980
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.0033666666666666667,
      "loss": 3.6877,
      "step": 1990
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.003333333333333333,
      "loss": 3.7135,
      "step": 2000
    }
  ],
  "max_steps": 3000,
  "num_train_epochs": 3,
  "total_flos": 2.77201350033408e+17,
  "trial_name": null,
  "trial_params": null
}
